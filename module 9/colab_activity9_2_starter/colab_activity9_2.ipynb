{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-df3789e08c2c11f0",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Colab Activity 9.2: Comparing the Ridge to Ordinary Least Squares (OLS)\n",
    "\n",
    "**Expected Time: 30 Minutes**\n",
    "\n",
    "\n",
    "This activity focuses on comparing the models resulting from a `LinearRegression` model compared to a low penalty and high penalty `Ridge` model.  A synthetic polynomial dataset is used to compare the resulting model shapes.  Please pay attention to the resulting complexity and size of the coefficients as the amount of regularization changes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-037b3b689cf300f2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### Index\n",
    "\n",
    "- [Problem 1](#Problem-1)\n",
    "- [Problem 2](#Problem-2)\n",
    "- [Problem 3](#Problem-3)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7ef7387ae6992bba",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "from sklearn import set_config\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "set_config(display=\"diagram\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0b9fffe5c7471665",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": "data = pd.read_csv('module 9/colab_activity9_2_starter/data/synthetic_9.4.csv')",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-87abae19c15360bf",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "X, y = data[['x']], data['y']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cf4c256adb042655",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "plt.scatter(X, y)\n",
    "plt.title('Synthetic Polynomial Data')\n",
    "plt.grid();"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fb885de724d2d5ca",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Problem 1\n",
    "\n",
    "#### Polynomial Features and Linear Regression Pipeline\n",
    "\n",
    "\n",
    "\n",
    "To begin, you are to construct a `Pipeline` object with the following steps:\n",
    "\n",
    "- A  `poly_features` generated using `PolynomialFeatures()`with `degree = 5` polynomial features and `include_bias = False`.\n",
    "- A `linreg` step generated using `LinearRegression()` with default values.\n",
    "\n",
    "Assign this pipeline to `ols_pipe`.\n",
    "\n",
    "Next, use the `fit` function to train your model on `X` and `y`.\n",
    "\n",
    "Finally, use the `predict` function to calculate your predictions of `X`; assign your result to `ols_preds` below."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c89d95891ebff354",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "\n",
    "\n",
    "ols_pipe = Pipeline([\n",
    "    ('poly_features', PolynomialFeatures(degree=5, include_bias=False)),\n",
    "    ('linreg', LinearRegression())\n",
    "])\n",
    "ols_pipe.fit(X, y)\n",
    "ols_preds = ols_pipe.predict(X)\n",
    "\n",
    "# Answer check\n",
    "ols_pipe"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "Xnp = X.to_numpy()\n",
    "plt.scatter(Xnp, y, label='data')\n",
    "plt.plot(Xnp, ols_preds, 'r--', label='ols predictions')\n",
    "plt.legend()\n",
    "plt.grid();"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3777ac6f5b99d6ec",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Problem 2\n",
    "\n",
    "#### Ridge model with small regularization penalty\n",
    "\n",
    "\n",
    "\n",
    "To begin, you are to construct a `Pipeline` object with the following steps:\n",
    "\n",
    "- A  `poly_features` generated using `PolynomialFeatures()`with `degree = 5` polynomial features and `include_bias = False`.\n",
    "- A `ridge_low` step generated using `Ridge()` with `alpha = 0.1`.\n",
    "\n",
    "Assign this pipeline to `ridge_low_pipe`.\n",
    "\n",
    "Next, use the `fit` function to train your model on `X` and `y`.\n",
    "\n",
    "Finally, use the `predict` function to calculate your predictions of `X`; assign your result to `ridge_low_preds` below. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6f4bd93473f8b792",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "\n",
    "\n",
    "ridge_low_pipe = Pipeline([\n",
    "    ('poly_features', PolynomialFeatures(degree=5, include_bias=False)),\n",
    "    ('ridge_low', Ridge(alpha=0.1))\n",
    "])\n",
    "ridge_low_pipe.fit(X, y)\n",
    "ridge_low_preds = ridge_low_pipe.predict(X)\n",
    "\n",
    "# Answer check\n",
    "ridge_low_pipe"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "Xnp = X.to_numpy()\n",
    "plt.scatter(Xnp, y, label='data')\n",
    "plt.plot(Xnp, ridge_low_preds, '--r', label='ridge predictions')\n",
    "plt.plot(Xnp, ols_preds, '--g', label='OLS predictions')\n",
    "plt.legend();"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c57bf71f9a40c343",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Problem 3\n",
    "\n",
    "#### High Regularization Ridge \n",
    "\n",
    "\n",
    "\n",
    "To begin, you are to construct a `Pipeline` object with the following steps:\n",
    "\n",
    "- A  `poly_features` generated using `PolynomialFeatures()`with `degree = 5` polynomial features and `include_bias = False`.\n",
    "- A `ridge_high` step generated using `Ridge()` with `alpha = 1000`.\n",
    "\n",
    "Assign this pipeline to `ridge_high_pipe`.\n",
    "\n",
    "Next, use the `fit` function to train your model on `X` and `y`.\n",
    "\n",
    "Finally, use the `predict` function to calculate your predictions of `X`; assign your result to `ridge_high_preds` below. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c46eadce84699f71",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "\n",
    "\n",
    "ridge_high_pipe = Pipeline([\n",
    "    ('poly_features', PolynomialFeatures(degree=5, include_bias=False)),\n",
    "    ('ridge_high', Ridge(alpha=1000))\n",
    "])\n",
    "ridge_high_pipe.fit(X, y)\n",
    "ridge_high_preds = ridge_high_pipe.predict(X)\n",
    "\n",
    "# Answer check\n",
    "ridge_high_pipe"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "Xnp = X.to_numpy()\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "ax[0].scatter(Xnp, y, label='data')\n",
    "ax[0].plot(Xnp, ridge_low_preds, '--r', label='ridge low predictions')\n",
    "ax[0].plot(Xnp, ols_preds, '--g', label='OLS predictions')\n",
    "ax[0].plot(Xnp, ridge_high_preds, '--', color='purple', label='ridge high predictions')\n",
    "ax[0].set_title('Comparing the shape of different models')\n",
    "ax[0].legend();\n",
    "ax[0].grid();\n",
    "ax[1].plot(ols_pipe.named_steps['linreg'].coef_, 'o', markersize=10, label='OLS Coefs')\n",
    "ax[1].plot(ridge_low_pipe.named_steps['ridge_low'].coef_, 'v', markersize=10, label='ridge low')\n",
    "ax[1].plot(ridge_high_pipe.named_steps['ridge_high'].coef_, '^', markersize=10, label='ridge high')\n",
    "ax[1].legend();\n",
    "ax[1].axhline(color='black')\n",
    "ax[1].grid();\n",
    "ax[1].set_title('Comparing the Coefficients');"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
